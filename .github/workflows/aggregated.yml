name: Update aggregated data

on: push #for testing
  # schedule:
    #- cron: '2 22 * * *' Is what we'd like to do, run daily overnight

jobs:
  fetch:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python 3.6
      uses: actions/setup-python@v1
      with:
        python-version: 3.6
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r aggregated_data/requirements.txt
    - name: Fetch aggregated data
      env:
        GS_CLIENT_ID: ${{secrets.GS_CLIENT_ID}}
        GS_CLIENT_SECRET: ${{GS_CLIENT_SECRET}}
      run: |
        python3 aggregated_data/fetch_gs_data.py outputs/aggregated
    - name: Commit files
      run: |
        git config --local user.email 'action@github.com'
        git config --local user.name 'Github Action'
        git add outputs/aggregated
        git commit -m 'Add updated GSQuant aggregated data'
    - name: Push changes # Uses the Github token so no triggering CI workflows
      uses: ad-m/github-push-action@master
      with:
        github_token: ${{secrets.GITHUB_TOKEN}}
